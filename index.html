<!--
  Copyright 2018 The Distill Template Authors

  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License.
-->
<!doctype html>

<head>
<script src="https://distill.pub/template.v2.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta charset="utf8">
</head>

<body>
  <d-front-matter>
    <script id='distill-front-matter' type="text/json">{
    "title": "Exemplar VAE",
    "description": "An exemplar based generative model for density estimation, representation learning, and generative data augmentation",
    "published": "April 1, 2020",
    "authors": [
      {
        "author":"Sajad Norouzi",
        "authorURL":"http://www.cs.toronto.edu/~sajadn/",
        "affiliations": [{"name": "University of Toronto", "url": "http://www.cs.toronto.edu"}]
      },
      {
        "author":"David Fleet",
        "authorURL":"http://www.cs.toronto.edu/~fleet/",
        "affiliations": [{"name": "University of Toronto", "url": "http://www.cs.toronto.edu"}]
      },
      {
        "author":"Mohammad Norouzi",
        "authorURL":"http://norouzi.github.io",
        "affiliations": [{"name": "Google Brain", "url": "https://g.co/brain"}]
      }
    ],
    "doi": "https://arxiv.org/pdf/1705.07120.pdf",
    "katex": {
      "delimiters": [
        {"left": "$$", "right": "$$", "display": false}
      ]
    }
  }</script>
  </d-front-matter>
  <d-title>
    <p>An exemplar based generative model useful for density estimation, representation learning, and generative data augmentation</p>
  </d-title>
  <d-byline></d-byline>
  <d-article>
    <figure style="grid-column: page">
        <img src="exemplar-vae-generation.svg" style="margin: 0;"/>
    </figure>
    <!-- <a class="marker" href="#section-1" id="section-1"><span>1</span></a> -->
    <h2>Motivation</h2>

        <figure style="grid-column: kicker  ">
            <img src="water_lilies.jpg" style="width: 100%; max-width: 204px; margin-top: 1rem;"/>
              <figcaption> The first image in google search result. Nice job!</figcaption>
        </figure>
    <p>
      Consider the problem of conditional image generation, given a natural
      language description of a scene such as:
        <br/> ''A woman is staring at Monet's Water Lilies''.</br>
      There are two general classes of methods for addressing this problem.
      One can resort to <em>exemplar based methods</em>, e.g., using web search engines to
      <a href="https://www.google.ca/search?tbm=isch&q=a+woman+is+staring+at+monet%27s+water+lilies&oq=a+woman+staring+at+Monet\%27s+Water+Lilies">retrieve photographs with similar captions</a>,
      and then editing the retrieved images to generate new ones.
      Alternatively, one can adopt <em>parametric models</em> such as deep neural
      networks optimized for text to image translation to synthesize new relevant scenes.
    </p>

    <p>
      This paper presents a probabilistic framework for exemplar based
      generative modeling using expressive neural nets. This framework
      combines the advantages of both exemplar based and parametric methods
      in a principled way and achieves superior results. We focus on simple
      unconditional generation tasks here, but the learning formulation and
      the methods developed are applicable to other applications including
      text to image translation and language modeling.
    </p>

    <p>
        Exemplar based methods depend on large and diverse datasets of
        exemplars and relatively simple machine learning algorithms, such as
        Parzen window
        estimation <d-cite key="parzen1962estimation"></d-cite> and
        conditional random fields <d-cite key="lafferty2001conditional"></d-cite>. They deliver
        impressive results on texture synthesis <d-cite key="efros1999texture"></d-cite>, image
        super resolution <d-cite key="freeman2002example"></d-cite>, and
        inpaiting <d-cite key="criminisi2003object, hays2007scene"></d-cite>, despite their
        simplicity.  These techniques can accommodate web scale datasets with
        a improvement in sample quality as the dataset size increases, without
        the need for further optimization of model parameters. The success of
        exemplar based methods hinges on the distance metric used to build a
        local density model for each neighborhood. Unfortunately, finding an
        effective distance metric in a high dimensional space is challenging
        on its own <d-cite key="xing2003distance, johnson2016perceptual"></d-cite>. Further,
        while exemplar based methods excel in interpolation tasks, they often
        underperform their parametric counterparts in extrapolation.</p>

  </d-article>

  <d-appendix>

      <h3>Contributions</h3>
      <p>Some text describing who did what.</p>
      <h3>Reviewers</h3>
      <p>Some text with links describing who reviewed the article.</p>

      <d-bibliography src="https://raw.githubusercontent.com/exemplar-vae/exemplar-vae.github.io/master/bibliography.bib">
      </d-bibliography>
  </d-appendix>

  <distill-footer>

  </distill-footer>

</body>